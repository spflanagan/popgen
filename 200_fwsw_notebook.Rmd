---
title: "FWSW lab Notebook"
author: "Sarah P. Flanagan"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: html_notebook
editor_options: 
  chunk_output_type: console
---

```{r setup}
knitr::opts_knit$set(root.dir='../fwsw_results/', fig.pos='H')
```

# 17 September 2019

My computer crashed -- 3DAL had been running for over 1600 hr and didn't even get through one replicate of one model. This is absolutely ridiculous. Luckily 254_2DoptNsim_TX_1 finished yesterday. Ah except it's not that it finished, it ran out of space! Crap. But it has finished 20 simulations so far. What's crazy to me is the variation in analysis times for the simulations -- from 5hr 49 min to 17 days! Once I restart my computer I'll run some more dadi combinations. maybe I can just do a bunch of 2D analyses and skip the 3D, unless Felipe sorts me out with something through MS Azure.

In the meantime, I'm going to work on an aspect of these analyses that is more within my control -- the Fst permutations.

```{r}
permuted_fsts<-readRDS("permuted_fsts.RDS")
```

So one of the issues with the permutations is that many of the loci are only polymorphic in one population, causing Fst to be 0, based on my calculations (because average Hs is the same as Ht). I could try another Fst calculation method but I'm not sure that will really help. But this should come out in the permutations? Are the permutations not permuting the map reliably? I think it should be. 

Looking at the variation in the Num1s after 10 permutations, it would seem that the permutations are working. What seems to be happening is that at some loci there is only one heterozygote so even if that individual gets switched it doesn't change things. 

I suppose the question is whether these perhaps-problematic loci are also problematic in the fst comparisons. The Fst output from permute.gwsca is the ACTUAL fst so I could plot those with CIs.

```{r gwscaPlot}
pf1<-fst.plot(permuted_fsts[[1]],bp.name="Pos",pt.cex = 1,axis.size = 1,pch=19)
# add lines
pos_fsts<-pf1[pf1$Fst>0,]
arrows(x0=pos_fsts$plot.pos,x1=pos_fsts$plot.pos,
       y0=pos_fsts$low_ci, y1=pos_fsts$upp_ci,
       col=c("darkgrey","lightgrey")[as.factor(pos_fsts$Chrom)],length=0)
```

Ok, so I calculated the confidence intervals around the permuted means, not the actual Fst values. 

So, how do I present these results? possibly not CIs. A difference between actual and permuted?

```{r}
par(mfrow=c(2,1))
pf1a<-fst.plot(permuted_fsts[[1]],fst.name = "Fst",bp.name="Pos",pt.cex = 1,axis.size = 1,pch=19,y.lim = c(0,1))
pf1p<-fst.plot(permuted_fsts[[1]],fst.name = "mean_perm",bp.name="Pos",pt.cex = 1,axis.size = 1,pch=19,y.lim = c(0,1))
arrows(x0=pf1p$plot.pos,x1=pf1p$plot.pos,
       y0=pf1p$low_ci, y1=pf1p$upp_ci,
       col=c("darkgrey","lightgrey")[as.numeric(pf1p$Chrom)%%2],length=0)
```

So they definitely are different. Maybe I can do a chi-squared test or something.


```{r}
fwsw.al<-read.delim("stacks/populations_subset75/batch_2.fst_ALFW-ALST.tsv")
fwsw.la<-read.delim("stacks/populations_subset75/batch_2.fst_ALST-LAFW.tsv")
fwsw.tx<-read.delim("stacks/populations_subset75/batch_2.fst_TXCC-TXFW.tsv")
fwsw.fl<-read.delim("stacks/populations_subset75/batch_2.fst_FLCC-FLFW.tsv")
```



# 9 September 2019

Ok, so that permuted Fsts thing works for permutations, but I think something odd is going on with the Fst calculations.

```{r}
permute.gwsca<-function(vcf,map1,nperms,z=1.96, maf.cutoff = 0.05,cov.thresh=0.2){
  # calculate the actuals
  actual_fsts<-gwsca(vcf,colnames(vcf)[1:9],
                     map1[map1[,2] %in% unique(map1[,2])[1],1],
                     map1[map1[,2] %in% unique(map1[,2])[2],1],
                     maf.cutoff=maf.cutoff,prop.ind.thresh=cov.thresh)
  # do the permutations
  perm_fsts<-lapply(1:nperms,function(i,vcf,map1){
    perm_map<-map1
    perm_map[,2]<-perm_map[,2][permute::shuffle(perm_map[,2])]
    perm_dat<-gwsca(vcf,colnames(vcf)[1:9],
                     perm_map[perm_map[,2] %in% unique(perm_map[,2])[1],1],
                     perm_map[perm_map[,2] %in% unique(perm_map[,2])[2],1],
                     maf.cutoff,cov.thresh)
   
    return(perm_dat)
  },vcf=vcf,map1=map1)
  
  # calculate stats
  fsts<-t(do.call(rbind,lapply(perm_fsts,'[[',"Fst"))) #extract permuted fsts
  perm_fst_mu<-rowMeans(fsts)
  perm_fst_sd<-apply(fsts,1,sd)
  perm_fst_ci<-z*perm_fst_sd/sqrt(nperms)
  fst_dat<-data.frame(cbind(actual_fsts,
                            n_perms=nperms,
                            mean_perm=perm_fst_mu,
                            low_ci=perm_fst_mu-perm_fst_ci,
                            upp_ci=perm_fst_mu+perm_fst_ci))
  return(fst_dat)
}
```
```{r}
source("../../gwscaR/R/gwscaR.R")
source("../../gwscaR/R/gwscaR_plot.R")
source("../../gwscaR/R/gwscaR_utility.R")
source("../../gwscaR/R/gwscaR_fsts.R")
source("../../gwscaR/R/gwscaR_popgen.R")
source("../../gwscaR/R/vcf2dadi.R")
```
```{r}

permuted_fsts<-readRDS("permuted_fsts.RDS")
vcf<-parse.vcf("stacks/populations_subset75/batch_2.pruned.vcf")
popmap<-data.frame(inds=colnames(vcf)[10:ncol(vcf)],
                   pops=gsub("sample_(\\w{4}).*","\\1",colnames(vcf)[10:ncol(vcf)]),
                   stringsAsFactors = FALSE)
pwise_maps<-list(popmap[popmap$pops %in% c("TXFW","TXCC"),],
                 popmap[popmap$pops %in% c("FLLG","FLCC"),],
                 popmap[popmap$pops %in% c("ALFW","ALST"),],
                 popmap[popmap$pops %in% c("LAFW","ALST"),])

TXmap<-popmap[popmap$pops %in% c("TXFW","TXCC"),]
perm_test<-permute.gwsca(vcf,TXmap,10,maf.cutoff=0,cov.thresh = 0)
```

Ok, now let's dive into this analysis. Using browser(), I deduced that this was a minimum allele frequency issue. Because the loci in this analysis have passed a global minor allele frequency threshold, I'm going to run with a maf=0. The other reason is that some of them are polymorphic only in one population, and the function currently only deals with loci that are polymoprhic in both populations. This is unfortunately most of them in the TX dataset so I might change the function. 

Now it seems to be working correctly so I'll apply it to the larger dataset.

```{r}
permuted_fsts<-lapply(pwise_maps,permute.gwsca,vcf=vcf,nperms=100, maf.cutoff=0)
saveRDS(permuted_fsts,"permuted_fsts.RDS")
```


# 5 September 2019

Returning to the idea of permutations...

I'll want to permute the labels in each pairwise comparison.

```{r}
vcf<-parse.vcf("stacks/populations_subset75/batch_2.pruned.vcf")

```

In some ways this might be easier to run in populations, but I want to try it here.

My gwscaR code isn't quite right for this because the population lists must be found in the individual IDs. So I need to re-make this using a population map framework. So here's the population map:

```{r}
popmap<-data.frame(inds=colnames(vcf)[10:ncol(vcf)],
                   pops=gsub("sample_(\\w{4}).*","\\1",colnames(vcf)[10:ncol(vcf)]),
                   stringsAsFactors = FALSE)
```

Now I want to do pairwise comparisons and permute those. 

```{r}
pwise_maps<-list(popmap[popmap$pops %in% c("TXFW","TXCC"),],
                 popmap[popmap$pops %in% c("FLLG","FLCC"),],
                 popmap[popmap$pops %in% c("ALFW","ALST"),],
                 popmap[popmap$pops %in% c("LAFW","ALST"),])
```

`gwscaR::fst.one.vcf` actually will work well -- as will `gwscaR::gwsca`. What I need to do for permutations is for each of these pairwise maps, I need to run a permutation. 

```{r}
permute.gwsca<-function(vcf,map1,nperms,z=1.96, maf.cutoff = 0.05,cov.thresh=0.2){
  # calculate the actuals
  actual_fsts<-gwsca(vcf,colnames(vcf)[1:9],
                     map1[map1[,2] %in% unique(map1[,2])[1],1],
                     map1[map1[,2] %in% unique(map1[,2])[2],1],
                     maf.cutoff,cov.thresh)
  # do the permutations
  perm_fsts<-lapply(1:nperms,function(i,vcf,map1){
    perm_map<-map1
    perm_map[,2]<-perm_map[,2][permute::shuffle(perm_map[,2])]
    return(gwsca(vcf,colnames(vcf)[1:9],
                     perm_map[perm_map[,2] %in% unique(perm_map[,2])[1],1],
                     perm_map[perm_map[,2] %in% unique(perm_map[,2])[2],1],
                     maf.cutoff,cov.thresh))
  },vcf=vcf,map1=map1)
  # calculate stats
  fsts<-t(do.call(rbind,lapply(perm_fsts,'[[',"Fst"))) #extract permuted fsts
  perm_fst_mu<-rowMeans(fsts)
  perm_fst_sd<-apply(fsts,1,sd)
  perm_fst_ci<-z*perm_fst_sd/sqrt(nperms)
  fst_dat<-data.frame(cbind(actual_fsts,
                            n_perms=nperms,
                            mean_perm=perm_fst_mu,
                            low_ci=perm_fst_mu-perm_fst_ci,
                            upp_ci=perm_fst_mu+perm_fst_ci))
  return(fst_dat)
}
```

```{r}
TXmap<-popmap[popmap$pops %in% c("TXFW","TXCC"),]
perm_test<-permute.gwsca(vcf,TXmap,10)

```

This seems like it will work, I think!

Let's try it on a larger scale:

```{r}
permuted_fsts<-lapply(pwise_maps,permute.gwsca,vcf=vcf,nperms=100)
saveRDS(permuted_fsts,"permuted_fsts.RDS")
```
Ok, I want to do permutations but I can't think about how to implement it right now. Looking at this, though there seems to be an issue, since Hs1 and Hs2 are non-zero but Hs, Ht, and Fst are 0 for some of these. I'll need to dig into this tomorrow.

# 28 August 2019

loading the file with diveRsity is pretty slow so I'm going to try subsetting it first. I'm gonna give the R package `genepopedit` a try.

```{r, eval=FALSE}
devtools::install_github("rystanley/genepopedit") #https://github.com/rystanley/genepopedit
```

```{r}
library(genepopedit)
source("../../gwscaR/R/gwscaR.R")
source("../../gwscaR/R/gwscaR_plot.R")
source("../../gwscaR/R/gwscaR_utility.R")
source("../../gwscaR/R/gwscaR_fsts.R")
source("../../gwscaR/R/gwscaR_popgen.R")
source("../../gwscaR/R/vcf2dadi.R")
library(fsthet)
source("../R/203_treemix_plotting_funcs.R")#I've modified these functions
library(knitr)
library(scales)

```
```{r}
gpop75<-my.read.genepop("stacks/populations_subset75/batch_2.genepop")
vcf<-parse.vcf("stacks/populations_subset75/batch_2.pruned.vcf")
```

It's not clear to me how to match up the genepop locus names and the IDs in the vcf file. I'm guessing that the genepop ones are ID_BP but I'm not sure. 

```{r}
gpop_ids<-as.numeric(gsub("X(\\d+)_\\d+","\\1",colnames(gpop75)[3:ncol(gpop75)]))
```
 Yes I think that's the case. `r length(gpop_ids %in% vcf$ID)` of the `r length(gpop_ids)` IDs are in the vcf file. and `r length(vcf$ID %in% gpop_ids)` of the `r length(vcf$ID)` vcf IDs are in the genepop file. The issue is that I don't know which ones I chose! Because it was done randomly and the POS is not the same as the basepair tacked onto the genepop IDs -- POS indicates the position on the chromosome, whereas the number in the genepop names is the location on the 95-bp locus.
 
The map file might be able to help me convert them

```{r}
map<-read.delim("stacks/populations_subset75/batch_2.plink.map",comment.char = "#",header=FALSE)
colnames(map)<-c("CHROM","ID_BP","X","POS")
map$ID<-as.numeric(gsub("(\\d+)_(\\d+)","\\1",map$ID_BP))
map$BP<-as.numeric(gsub("(\\d+)_(\\d+)","\\2",map$ID_BP))
# Map positions start from 1, vcf from 0
map_pruned<-map[paste(map$POS+1,map$ID,sep="_") %in% paste(vcf$POS, vcf$ID,sep="_"),]
gpop75_pruned<-gpop75[,c(colnames(gpop75)[1:2],colnames(gpop75)[colnames(gpop75) %in% paste0("X",map_pruned$ID_BP)])]
```

Woohoo, this seems to have worked!

Now I need to turn this back into genepop file format to work with diveRsity...

```{r}
library(genepopedit)
genepop_unflatten(gpop75_pruned,"stacks/populations_subset75/batch_2.pruned.genepop")

```

Ok, this seems to work. 

```{r}
library(diveRsity)
source("../R/readGenepop_modified.R") # need to load this after divRsity to mask the package fx
pop75_div<-fastDivPart(infile=gpop75_pruned,gp = 2) #readGenepop(infile="stacks/populations_subset75/batch_2.pruned.genepop",gp = 2)
```

This is not working! I ended up re-writing some of the code that parses the genepop files because diveRsity wasn't correctly parsing my genepop file for some reason (something to do with the POP specifications, as far as I can tell -- which came from genepopedit and before that from Stacks).

However, this does not get past the issues, as far as I can tell. So perhaps I should retire the idea of using this package and/or post an issue on the github. I think I should maybe abandon this and perform permutations/bootstraps on my own. 

So if I'm going to do permutations or bootstraps I might have to write it myself.

```{r}
popmap<-data.frame(pop=gsub("sample_([A-Z]{4}).*","\\1",colnames(vcf)[10:ncol(vcf)]),
                   sample=colnames(vcf)[10:ncol(vcf)],stringsAsFactors = FALSE)

```



### Pcadapt

I managed to run pcadapt again but I need a better overall plan before doing anything with the outliers.



# 27 August 2019

I'm going to try the diveRsity package.

```{r}
library(diveRsity)
pop75<-readGenepop("stacks/populations_subset75/batch_2.genepop")
vcf<-parse.vcf("stacks/populations_subset75/batch_2.pruned.vcf")

divstats<-bigDivPart(gpop75)
```

This is taking far too long. I should try this at work tomorrow.


# 19 August 2019

I'm running the heterogeneous migration models for FL on my local machine and today requested that dadi be installed on abacus. I've also prepared scripts to run FLFW vs ALFW, FLFW vs TXFW, and TXFW vs ALFW. I may need to modify those scripts further if I'm going to run them on abacus, but for now they're a start.


# 14 August 2019

I've been putting off returning to this because I don't really know what to do. With regards to dadi, I think there are a few things I need to do:

1. Incorporate admixture into models. 
2. Run models between freshwater populations, specifically TX vs FL, TX vs AL/LA, and FL vs AL/LA. I'm worried about a 3D model taking forever, so maybe run AL vs LA? Ugh this will take FOREVER. Maybe I can figure out how to run these on the server?

Ok, I'm going to read that Rougeux paper and consider using his models. Rougeux et al used 4 basic models with 13 extensions. They used strict isolation (SI), isolation with migration (IM) ancient migration (AM) and secondary contact (SC). The extensions capture effect of selection inducing reduced gene flow around loci associated with adaptive divergence. 

The way this is written makes me think that they fit the basic models and then incorporated heterogeneous gene flow plus background selection (considering local variation in Ne). So, I'm going to try to use their code to add variation in migration and Ne across the genome into the asym_mig code. I think I've done this successfully! So now to run it for FL...I've updated the 252_2DFL.py script and now will try running it on my computer. 

# 9 August 2019

Gutenkunst wrote back, saying "The suitability of dadi for this depends on what assumptions you’re willing to make. Are you assuming your RADseq loci are independent? If not, you’ll need a much more complex simulation scheme to capture that dependence anyways. If yes, then you don’t need to use coalescent simulations." I guess he doesn't want to just answer my questions. 

But I guess it brings me back to the question of what I'm even doing, in a way. Maybe I should focus on running the models with heterogeneous selection first. Do I even need to identify outliers? probably not to this extent. Blargh. I should probably run some additional models. 

I am looking at Rougeux's code: https://github.com/crougeux/Dadi_v1.6.3_modif/blob/master/Dadi_studied_model/00_inference/modeledemo_mis_new_models.py

for inspiration about the heterogeneous effective population sizes.

```{python}
def SI2N(params, (n1,n2), pts):
    nu1, nu2, Ts, nr, bf, O = params
    """
    Model with split and complete isolation, heterogenous effective population size
        (2 classes, shared by the two populations = background selection)
    nu1: Size of population 1 after split.
    nu2: Size of population 2 after split.
    Ts: The scaled time of the split
    n1,n2: Size of fs to generate.
    nr: Proportion of non/low-recombining regions
    bf : Background factor (to which extent the effective population size is reduced in the non-recombining regions)
    O: The proportion of accurate orientation
    pts: Number of points to use in grid for evaluation.
    """
    # Define the grid we'll use
    xx = dadi.Numerics.default_grid(pts)

    # Spectrum of non-recombining regions
    # phi for the equilibrium ancestral population
    phinr = dadi.PhiManip.phi_1D(xx)
    # Now do the divergence event
    phinr = dadi.PhiManip.phi_1D_to_2D(xx, phinr)
    # We set the population sizes after the split to nu1 and nu2	
    phinr = dadi.Integration.two_pops(phinr, xx, Ts, nu1*bf, nu2*bf, m12=0, m21=0)
    # Finally, calculate the spectrum.
    # oriented
    fsnrO = dadi.Spectrum.from_phi(phinr, (n1,n2), (xx,xx))
    # mis-oriented
    fsnrM = dadi.Numerics.reverse_array(fsnrO)
    
    
	# Spectrum of recombining regions
    # phi for the equilibrium ancestral population
    phir = dadi.PhiManip.phi_1D(xx)
    # Now do the divergence event
    phir = dadi.PhiManip.phi_1D_to_2D(xx, phir)
    # We set the population sizes after the split to nu1 and nu2
    phir = dadi.Integration.two_pops(phir, xx, Ts, nu1, nu2, m12=0, m21=0)
    # Finally, calculate the spectrum.
    # oriented
    fsrO = dadi.Spectrum.from_phi(phir, (n1,n2), (xx,xx))
    # mis-oriented
    fsrM = dadi.Numerics.reverse_array(fsrO)

    ### Sum the two spectra in proportion O
    fs= O*(nr*fsnrO + (1-nr)*fsrO) + (1-O) *(nr*fsnrM + (1-nr)*fsrM)

    return fs

```

I should be able to adapt this in my code, but honestly 4:30pm on a Friday is not the time to be doing this. I will work on this on Monday, I think.

Remember to be inspired by this paper: https://onlinelibrary.wiley.com/doi/full/10.1111/jeb.13482

# 8 August 2019

I'm using the code in 257_debug_ms.py to make the comparison plots.

Other things I can do: 
1. re-evaluate calculation of theta by scouring the dadi user webpage
2. run many mas sims and average the results (or increase iter?)

regarding theta, on this group (https://groups.google.com/forum/#!searchin/dadi-user/dadi$20to$20ms|sort:date/dadi-user/DYrpTHCcC_I/nl3f2eGSAQAJ) Ryan says to use  `L = 3e6 * 56,343/123,797` for someone with 3 million sites (RAD loci), a total of 123797 SNPs, of which 56343 were used. That L should then get plugged into `4*Ne*mu*L`, and dadi's theta is `4*Ne*mu*L`. So to get the ms theta, which is `4*Ne*mu*L`, we divide dadi's theta by L. So what I need to do is get L. Let's write out the variables. `L = (num loci)*(num SNPs in analysis)*(total num SNPs)` - which is different from what I did (`dadi-theta*Llocus/Ltotal` [`227.83*95/(12103*251339*95/1370051)=0.1026112`]), and does not include the length of the loci.

However, this post (https://groups.google.com/forum/#!searchin/dadi-user/dadi$20to$20ms|sort:date/dadi-user/1Chc8kXrWE0/NuB4d4X2BwAJ) uses the length of the SNPs. They did `dadi-theta*(length of sequence)/(total length of sequences used) `

I've increased the iter substantially and it is very slow, but when it is done I will test out averaging spectra (just try doing mean() with two spectra objects I guess?). Using mean does not work! Nor does dadi.Spectrum.mean(fs1,fs2)

So I posted this on the forum:

```

Thank you for your response! I have a few follow-up questions:

  1.  To calculate theta I was following what the original post had done, which was: (dadi's theta estimate)*(individual rad locus length)/(total estimated length (L)), where L = (length of RAD loci)*(total number of RAD loci)*(number of SNPs in the analysis)/(total number of SNPs). Your response prompted me to scour the dadi-user group more thoroughly and I see that this estimate differs slightly from others that have been suggested. For instance, in this post, the conversion to ms theta is (daid-theta)*(length of sequence)/(total length of sequence used), and in this post, the conversion appears to be (dadi-theta)/L, where L = (total number of rad loci)*(number of SNPs in the analysis)*(total number of SNPs). What would you say is the best way to convert dadi's estimated theta to the input theta for ms for RAD-seq data?
  2.  I think I am a bit confused about specifying the number of loci in ms. I thought the number of iterations is equivalent to the number of SNPs simulated by ms (and I had used the number of SNPs in my dataset) -- is there a different way to specify the number of SNPs, and the number of SNPs per locus, in ms?
   3. How do you recommend that I average the spectra produced by multiple ms runs to compare the models?

Thank you so much for your help and the time you put into answering all of the questions here on the forum!

```

And now I just need to wait for Gutenkunst to answer.

He responded already! He said:

```
Maybe it’s time to back up here. Why are you running ms again? Typically we would only do coalescent simulations if we wanted to test how linkage affects our data. But if you’re simulating RAD seq loci independently and only taking one SNP per locus, then you’re generating data with no linkage anyways. In this case, the only difference between dadi and ms would be if you made an error in converting model specifications.

If you’re assuming you’re loci are unlinked, then the likelihood dadi calculates is correct, and you can do model selection with likelihood ratio tests, etc.
```

So I responded:

```
I would like to compare the distribution of Fsts in the observed data to a null distribution, so I'm trying to simulate data using the best-inferred model for my dataset. I was under the impression that dadi does not simulate data that can be used for this purpose, so I'm trying to use ms to generate simulated data. Do you have a suggestion for a better way to do this?
```

Now it's the waiting game again

# 1 August 2019

This is the response from Ryan Gutenkunst:
```
Hi Sarah,

Your demographic parameter conversion looks fine to me. But I don’t follow the theta conversion formula you’re using. You want your bootstrap data sets to have the same total theta as your original data data set. Are you downsampling the ms simulations to get to one SNP per locus?

It’s hard to tell whether your ms and dadi simulations agree, because the ms simulation is so sparse. Run many ms simulations then average the results to compare with the dadi model (and look at the residuals to see if there is systematic difference).

Best,
Ryan
```

And I find that response to be rather confusing. So....??? A few things to unpack:
1. Check that I've calculated theta correctly and re-write the equation.
2. How many SNPs per locus am I specifying in ms??
3. Run more ms sims and average the results 
4. How do I look at residuals? 
    Using dadi.Plotting.plot_2d_comp_multinomial between the data (fl_optimized) and models looks like it should work. I was struggling at first because I'd used different projection #s but I think it's better now?
    
I'm finding this VERY frustrating so I'm going to move onto something else for right now.


# 31 July 2019

I got ms to work within dadi by adding the msdir to the $PATH (duh). The issue was that python couldn't find the ms program.
Ok, so now troubleshooting the odd looking spectrum. I need to compare model with different cases, both the ms model and the dadi model. 
After trying a number of different models and still not finding a particularly good fit, I found that the most effective approach is to increase theta -- which implies that my estimates are not very good.

If I remove the -ej part of the ms code (but keep migration and ns) it works better. So I should probably check that -ej is the appropriate way to specify these models in the ms manual. I feel fairly confident that this is specified correctly...perhaps I should post my issue on the google group and get some feedback. 

I posted this on the dadi forum, in response to the thread from 2018 that inspired me:

```
Were you able to resolve this issue? I am running into a similar issue. In my case, I have ddRADseq data and I generated 251339 RAD loci (each 95bp long) with a total of 1370051 SNPs. I filtered and down-sampled to a dataset with 12103 unpolarized SNPs, each from a different RAD locus. I compared a number of models using Daniel Portik's dadi-pipeline and a model with ongoing asymmetric migration since a population split had the best fit.

The following forward-in-time dadi parameters were estimated from the best-fitting model:

Size of population 1 after split (nu1) = 0.1317
Size of population 2 after split (nu2) = 8.4225
Time in the past of split in units of 2*Na generations (T) = 0.1441
Migration from pop 2 to pop 1 (m12) = 0.7777
Migration from pop 1 to pop 2 (m21) = 0.0561
theta = 227.83

Based on what I've seen on this forum, I converted these parameters to ms arguments as follows:
-m 1 2 1.5554 [m12*2]
-m 2 1 0.1122 [m21*2]
-n 1 0.1317
-n 2 0.84225
-ej 0.07205 2 1 [T/2]

For theta, I converted it using the previously-recommended formula of (dadiTheta * locusLength) / ( (numSNPused * numLoci * locusLength) / totalNumSNPs ), which was:
-t = (227.83  * 95) / ( (12103 * 251339 * 95) / 1370051 )  = 0.1026112

like this:
core="-m 1 2 1.5554 -m 2 1 0.1122 -n 1 0.1317 -n 2 8.4225 -ej 0.07205 2 1"
command=dadi.Misc.ms_command(theta=0.1026112, ns=(60,70), core=core, iter=12103)
ms_fs=dadi.Spectrum.from_ms_file(os.popen(command))
folded_sfs=dadi.Spectrum.fold(ms_fs)
dadi.Plotting.plot_single_2d_sfs(folded_sfs,vmin=0.000001)


The sfs of asym_mig with these parameters looks like this:

FL_asym_mig_folded.png

But the output of the ms run above looks like this:

FL_ms_asym_mig_folded.png


Following the suggestions in this post, I tested it with equal migration between the two populations, no migration, and without the -ej term (the attached script has all of the code for these exploratory analysis). I found that removing the -ej term improved the ms-simulated sfs:

FL_ms_asym_mig_folded_noEj.png
However I'm not convinced that this ms model is the appropriate one for my dadi model.

Is anyone able to spot an issue in my implementation of the ms code? Has anyone successfully solved this type of issue?

Thank you in advance for your help!

Sarah

Attached: 257_debug_ms.py
```


Here are some of the things I tried:

```{python}
def no_divergence(notused, ns, pts):
    """
    Standard neutral model, populations never diverge.
    """
    
    xx = Numerics.default_grid(pts)
    
    phi = PhiManip.phi_1D(xx)
    phi = PhiManip.phi_1D_to_2D(xx, phi)
    
    fs = Spectrum.from_phi(phi, ns, (xx,xx))
    return fs


def no_mig(params, ns, pts):
    """
    Split into two populations, no migration.

    nu1: Size of population 1 after split.
    nu2: Size of population 2 after split.
    T: Time in the past of split (in units of 2*Na generations) 
    """
    nu1, nu2, T = params

    xx = Numerics.default_grid(pts)

    phi = PhiManip.phi_1D(xx)
    phi = PhiManip.phi_1D_to_2D(xx, phi)

    phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=0, m21=0)

    fs = Spectrum.from_phi(phi, ns, (xx,xx))
    return fs


def sym_mig(params, ns, pts):
    """
    Split into two populations, with symmetric migration.

    nu1: Size of population 1 after split.
    nu2: Size of population 2 after split.
    T: Time in the past of split (in units of 2*Na generations) 
    m: Migration rate between populations (2*Na*m)
    """
    nu1, nu2, m, T = params

    xx = Numerics.default_grid(pts)

    phi = PhiManip.phi_1D(xx)
    phi = PhiManip.phi_1D_to_2D(xx, phi)

    phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m, m21=m)

    fs = Spectrum.from_phi(phi, ns, (xx,xx))
    return fs

# Let's try it without the asymmetric migration
m = mean([m12,m21]) #0.4169
sym_mig_fs = sym_mig(params=(nu1,nu2,m,T),ns=ns,pts=pts)
sym_mig_folded = dadi.Spectrum.fold(sym_mig_fs)
dadi.Plotting.plot_single_2d_sfs(sym_mig_folded,vmin=0.000001)

core="-m 1 2 0.8338 -m 2 1 0.8338 -n 1 0.1317 -n 2 8.4225 -ej 0.07205 2 1"
command=dadi.Misc.ms_command(theta=0.1026112, ns=(60,70), core=core, iter=12103)
ms_fs=dadi.Spectrum.from_ms_file(os.popen(command))
folded_sfs=dadi.Spectrum.fold(ms_fs)
dadi.Plotting.plot_single_2d_sfs(folded_sfs,vmin=0.000001) # this is still not great.


# no migration

no_mig_fs = no_mig(params=(nu1,nu2,T),ns=ns,pts=pts)
no_mig_folded = dadi.Spectrum.fold(no_mig_fs)
dadi.Plotting.plot_single_2d_sfs(no_mig_folded,vmin=0.000001)

core="-n 1 0.1317 -n 2 8.4225 -ej 0.07205 2 1"
command=dadi.Misc.ms_command(theta=0.1026112, ns=(60,70), core=core, iter=12103)
ms_fs=dadi.Spectrum.from_ms_file(os.popen(command))
folded_sfs=dadi.Spectrum.fold(ms_fs)
dadi.Plotting.plot_single_2d_sfs(folded_sfs,vmin=0.000001) # this is still not great.

# no divergence -- ms can't converge
no_div_fs = no_divergence([nu1,nu2],ns=ns,pts=pts)
no_div_folded = dadi.Spectrum.fold(no_div_fs)
dadi.Plotting.plot_single_2d_sfs(no_div_folded,vmin=0.000001)

core="-n 1 0.1317 -n 2 8.4225"
command=dadi.Misc.ms_command(theta=0.1026112, ns=(60,70), core=core, iter=12103)
ms_fs=dadi.Spectrum.from_ms_file(os.popen(command))
folded_sfs=dadi.Spectrum.fold(ms_fs)
dadi.Plotting.plot_single_2d_sfs(folded_sfs,vmin=0.000001) # this is still not great.

# what about a different theta?
core="-m 1 2 0.8338 -m 2 1 0.8338 -n 1 0.1317 -n 2 8.4225 -ej 0.07205 2 1"
command=dadi.Misc.ms_command(theta=.05, ns=(60,70), core=core, iter=12103)
ms_fs=dadi.Spectrum.from_ms_file(os.popen(command))
folded_sfs=dadi.Spectrum.fold(ms_fs)
dadi.Plotting.plot_single_2d_sfs(folded_sfs,vmin=0.000001) # this is still not great.

# a different time + no migration? ms t = dadi T/2
asym_mig_fs = asym_mig(params=(nu1,nu2,0,0,1),ns=ns,pts=pts)
asym_mig_folded = dadi.Spectrum.fold(asym_mig_fs)
dadi.Plotting.plot_single_2d_sfs(asym_mig_folded,vmin=0.000001)

core="-m 1 2 0 -m 2 1 0 -n 1 0.1317 -n 2 8.4225 -ej 0.5 2 1"
command=dadi.Misc.ms_command(theta=0.1026112, ns=(60,70), core=core, iter=12103)
ms_fs=dadi.Spectrum.from_ms_file(os.popen(command))
folded_sfs=dadi.Spectrum.fold(ms_fs)
dadi.Plotting.plot_single_2d_sfs(folded_sfs,vmin=0.000001)

# a different time + sym migration? ms t = dadi T/2
asym_mig_fs = asym_mig(params=(nu1,nu2,m12,m12,1),ns=ns,pts=pts)
asym_mig_folded = dadi.Spectrum.fold(asym_mig_fs)
dadi.Plotting.plot_single_2d_sfs(asym_mig_folded,vmin=0.000001)

core="-m 1 2 1.5554 -m 2 1 1.5554 -n 1 0.1317 -n 2 8.4225 -ej 0.5 2 1"
command=dadi.Misc.ms_command(theta=0.1026112, ns=(60,70), core=core, iter=12103)
ms_fs=dadi.Spectrum.from_ms_file(os.popen(command))
folded_sfs=dadi.Spectrum.fold(ms_fs)
dadi.Plotting.plot_single_2d_sfs(folded_sfs,vmin=0.000001)
# Increasing theta seems to help -- perhaps my theta estimate is not appropriate?


os.chdir("~/Research/popgen/fwsw_results/dadi_analysis")
dd = dadi.Misc.make_data_dict ( "fwsw75.dadi.snps" )
fl = dadi.Spectrum.from_data_dict(dd , pop_ids =[ 'FLLG','FLCC' ],projections =[70,61] ,polarized = False )  #polarized = False creates folded spectrum

os.chdir(fl_dir)

pts = [ 220,240 ]

#Provide best optimized parameter set for empirical data.
#These will come from previous analyses you have already completed (above)
emp_params = [0.1317,8.4225,0.7777,0.0561,0.1441]

#Indicate whether your frequency spectrum object is folded (True) or unfolded (False)
fs_folded = True

#Fit the model using these parameters and return the folded model SFS (scaled by theta).
#Here, you will want to change the "sym_mig" and sym_mig arguments to match your model function,
#but everything else can stay as it is. See above for argument explanations.
scaled_fl = Optimize_Empirical(fl, pts, "Empirical", "asym_mig", asym_mig, emp_params, fs_folded=fs_folded)




```

Also worth keeping, for inspiration/guidance, is this github site that converts ms into fst type data:
https://github.com/molpopgen/msstats

# 30 July 2019

I'm moving forward thinking about how to use the dadi simulations to analyze my Fst results (with the FL population as my first pass).
The dadi simulations only give me a sense of whether my parameters are 'good' or not, and I think they are (given the chi-squared distributions etc). I should maybe also look at the parameters as well. Once I'm confident in my parameter estimates, I'll use them to run ms. 

So looking at histograms of the simulated values, the parameters I used definitely fall within the distributions. The m21 parameter seems a bit low comopared to many of the estimates, since the median estimate is 0.3838, the variance is 0.03662088, and my initial parameter was 0.0561. I'll run with it for now, but I should maybe test different runs of ms just to be sure.

To run ms I need to estimate theta (which comes from the time parameter??) and 4N0m. Also, the population sizes need to be relative to N0. In the dadi manual, it states:
```
So to convert from a time in ∂a∂i to a time in ms, divide by 2.
Migration rates are given in units of M ij = 2N ref m ij . Again, this differs from ms, where
the scaling factor is 4N ref generations. So to get equivalent migration (m ij ) in ms for a given
rate in ∂a∂i, multiply by 2
```

Therefore, for Florida, I need to use time = `0.1441/2`, m12 = `0.7777*2`, m21 = `0.0561*2`.  

On the dadi forum was a question posed using this model (https://groups.google.com/forum/#!searchin/dadi-user/ms%7Csort:date/dadi-user/N623Qe75iDs/neuuqEyUAwAJ):

```

Forward in time dadi parameters:
theta = 5911.67
pop 1 relative pop size post divergence = .1009
pop 2 relative pop size post divergence = .5933
T1, time from divergence until gene flow ceases = 5.3655
T2, time from cessation of gene flow until present = 0.0269
m12 = migration from pop 2 into 1 = 1.1616
m21 = migration from pop 1 into 2 = 0.4132
pop 1 relative pop size after size change = 29.9198
pop 2 relative pop size after size change = 8.7145

To simulate unlinked RAD loci, I generate a single-locus ms command by adjusting theta to be locus specific: 5911.67 * 94/3451628, i.e. multiply theta x individual rad locus length/total estimated length (L).


MS SIM SETUP
Basically, I simulate the set of unlinked rad loci and sum their respective sfs:

ms_fs = dadi.Spectrum.from_ms_file(popen('ms 306 56055 -t 0.160995617141 -I 2 91 215 -n 1 29.9198 -n 2 8.7145 -en 0.01345 1 0.1009 -en 0.01345 2 0.5933 -em 0.01345 1 2 0.8264 -em 0.01345 2 1 2.3232 -ej 2.6962 1 2),average=False)
folded_sfs=dadi.Spectrum.fold(ms_fs)
fig = pylab.figure(1)
fig.clear()
dadi.Plotting.plot_single_2d_sfs(folded_sfs,vmin=0.005)

note that the vmin setting was the same used for the plotting of the data and dadi inferred sfs.

MS ARGS IN DETAIL
-n 1 29.9198 : relative pop size of pop 1 (post expansion) at present
-n 2 8.7145 : relative pop size of pop 2 (post expansion) at present
-en 0.01345 1 0.1009: going backward in time, pop 1 size changes, in ms units, at 0.0269/2 = 0.01345 to .1009
-en 0.01345 2 0.5933 : similarly, pop 2 size changes at same time as pop 1 to .5933 

### time parameter conversions ###
dadi parameters are forward in time, while ms is backwards. m12-dadi, the fraction of pop 1 comprised of migrants from pop 2, is equivalent in coalescent terms to m21 for ms. thus, given that dadi rates are multiplied by 2 to get equivalent ms rates:

 -em 0.1345 1 2 0.8264  : M12, the # of individuals from pop 1 comprised of backward in time migrants from pop 2
 -em 0.1345 2 1 2.3232 : M21 the # of individuals from pop 2 comprised of backward in time migrants from pop 1
 -ej 2.6962 1 2 : the full length of the genealogy in ms units is (T1+T2)/2 = (5.3655 + 0.0269)/2 = 2.6962, at which time all lineages from population 1 are moved to population 2
 
```

So what this tells me is that I can run ms from within dadi!
And The conversions I need to make are not exactly what I had thought. Information I need: number of total RAD loci and length of RAD loci. 

Then, I'll have the following parameters:

nsam = n1 + n2 [82 + 94]
nreps = NUMSNPS [12103]
-t = `dadi-theta*Llocus/Ltotal` [`227.83*95/(12103*251339*95/1370051)=0.1026112`]
-m 1 2 = `2*m12` [`2*0.7777`=1.5554]
-m 2 1 = `2*m21` [`2*0.0561`=0.1122]
-n 1 nu1 [0.1317] (size of pop 1 after split at time T)
-n 2 nu2 [2 8.4225] (size of pop 2 after split at time T)
-ej T/2 2 1 [`0.1441/2`=0.07205 2 1] (combine the populations at time T)

According to the last version of the manuscript, I had 194294 RAD loci, which are 95 bp long, and I have 12103 SNPs in the analysis. 
But according to the sstacks log, I have 251339 loci in the catalog, and there are 1370051 SNPs in batch_2.catalog.snps.tsv. So, I now have:

ms 176 12103 -t 0.1026112 -I 2 82 94 -m 1 2 1.5554 -m 2 1 0.1122 -en 0.07205 1 0.1317 -en 0.07205 2 8.4225

Ok, this is actually wrong -- the ns are the current population sizes, which formed at time T, so I need to use -ej. 
This should be the code:
ms 176 12103 -t 0.1026112 -I 2 82 94 -m 1 2 1.5554 -m 2 1 0.1122 -n 1 0.1317 -n 2 8.4225 -ej 0.07205 2 1

Now the question is whether I use command-line ms, the ms built into dadi, or msprime (which was recommended by Gutenkunst on another forum post). 

```{python}
import os
import dadi
ms_fs=dadi.Spectrum.from_ms_file(os.popen('ms 176 12103 -t 0.1026112 -I 2 82 94 -m 1 2 1.5554 -m 2 1 0.1122 -n 1 0.1317 -n 2 8.4225 -ej 0.07205 2 1'))
```
Running the above does not work. But the same commands run in ms, and I was able to read them into dadi - but the spectrum looks off. I probably need to troubleshoot like the OP of the above information did, but I'm going to come back to that.

I got this to work:


```{python}
import os
import dadi
command=dadi.Misc.ms_command(theta=0.1026112, ns=(82,94), core=core, iter=12103)
```

but I still get an error when trying to run ms in dadi. Tomorrow I will try to install msprime and give that a try.

I also found some models for heterogeneous migration across the genome:  https://github.com/crougeux/Dadi_v1.6.3_modif/blob/master/Dadi_studied_model/00_inference/modeledemo_mis_new_models.py

# 29 July 2019

Gutenkunst wrote back:

```
Hello Sarah,

Attached is the script I used look at your spectra more. You’ll see that the negative values in each of the integrated spectra and the final spectrum itself are very small. If we look at the plot, the only values < 1e-12 (and thus all the negative values) are in the lower right-hand corner. If not much of your data lies in that corner, then you have nothing to worry about.

Best,
Ryan
```

with this script attached:

```{python}
from asym_mig_test import *

print('Minimum value in fs200: {0}'.format(fs200.min()))
print('Minimum value in fs250: {0}'.format(fs250.min()))
print('Minimum value in fs300: {0}'.format(fs300.min()))

spectra = [fs200,fs250,fs300]
xs = [_.extrap_x for _ in spectra]
fs_extrap = dadi.Numerics.quadratic_extrap(spectra, xs)

print('Minimum value in extrapolated spectrum: {0}'.format(fs_extrap.min()))

dadi.Plotting.plot_single_2d_sfs(fs_extrap, vmin=1e-12)

```

![2D asym_mig spectrum]("asym_mig_test.png")

Just to double check that my data aren't in that lower right-hand corner, I re-plotted my TX data with vmin=1e-12 and got this:

![2D data spectrum]("dadi_analysis/TX2D/TX_2d_sfs_smallvmin.png")

And that plot also has empty space in the bottom right-hand corner, so I think it's ok. Which means that I can ignore the warnings and move forward with my analyses of the TX runs. How many have I run, and do I need to run more? I don't think so, I have a lot of runs in the TX2D folder.

Analyzing those, I find that sym_mig_size is the best model, with optimal parameters 5.6521,4.4595,1.0109,19.9392,0.4646,1.3392,0.4042 (nu1a,nu2a,nu1b,nu2b,m,T1,T2). So I've now started the simulation code (254_2DoptNsim.py) with the TX dataset. The next big question to answer (other than how can I speed up the 3D analysis?) is how to simulate data in a way that will help me interpret my Fst values. I'm not sure that I can easily do that with dadi, I might need to use ms.


# 22 July 2019

I submitted this script to the dadi webpage for Ryan Gutenkunst to help me analyze the spectra:

```{python 255_asym_mig}
'''
Running asym_mig to compare frequency spectra
'''

import os
import numpy
import dadi
import pylab
from datetime import datetime
from dadi import Numerics, PhiManip, Integration
from dadi.Spectrum_mod import Spectrum



def asym_mig(params, ns, pts):
    """
    Split into two populations, with different migration rates.

    nu1: Size of population 1 after split.
    nu2: Size of population 2 after split.
    T: Time in the past of split (in units of 2*Na generations) 
    m12: Migration from pop 2 to pop 1 (2*Na*m12)
    m21: Migration from pop 1 to pop 2
	"""
    nu1, nu2, m12, m21, T = params
    xx = Numerics.default_grid(pts)
    
    phi = PhiManip.phi_1D(xx)
    phi = PhiManip.phi_1D_to_2D(xx, phi)
    
    phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m12, m21=m21)
    fs = Spectrum.from_phi(phi, ns, (xx,xx))
    
    return fs    


# Set the parameters (from a run that resulted in lots of warnings)
nu1 = 1.01
nu2 = 15.4299
m12 = 0.9824
m21 = 1.1719
T = 3.6611
ns = [46,60]

# First set of points
pts = 200
xx = Numerics.default_grid(pts)
phi = PhiManip.phi_1D(xx)
phi = PhiManip.phi_1D_to_2D(xx, phi)
phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m12, m21=m21)
fs200 = Spectrum.from_phi(phi, ns, (xx,xx))

# Second set of points
pts = 250
xx = Numerics.default_grid(pts)
phi = PhiManip.phi_1D(xx)
phi = PhiManip.phi_1D_to_2D(xx, phi)
phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m12, m21=m21)
fs250 = Spectrum.from_phi(phi, ns, (xx,xx))

# Third set of points
pts = 300
xx = Numerics.default_grid(pts)
phi = PhiManip.phi_1D(xx)
phi = PhiManip.phi_1D_to_2D(xx, phi)
phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m12, m21=m21)
fs300 = Spectrum.from_phi(phi, ns, (xx,xx))


```

This is in response to his email:

```
Hello Sarah,

You'll need to compare the numerical values in the spectra, using numpy functions. If you're not comfortable doing that, I can help if you send a self-contained script that generates your model and spectra.

Best,
Ryan
```

# 19 July 2019

Ok, returning to how to actually run this stuff. I want to run something like:

```{python asym_mig_goal}
asym_mig(params=[1.01,15.4299,0.9824,1.1719,3.6611], ns=[46,60] , pts=[200]) #ns are sample sizes
```

but this throws an error, "TypeError: int() argument must be a string or a number, not 'list'"

I'm not sure where this is going wrong, but it seems to be in the creation of the pts. Maybe I should run asym_mig step by step? This is asym_mig:

```{python asym_migfxn}
def asym_mig(params, ns, pts):
    """
    Split into two populations, with different migration rates.

    nu1: Size of population 1 after split.
    nu2: Size of population 2 after split.
    T: Time in the past of split (in units of 2*Na generations) 
    m12: Migration from pop 2 to pop 1 (2*Na*m12)
    m21: Migration from pop 1 to pop 2
	"""
    nu1, nu2, m12, m21, T = params
    xx = Numerics.default_grid(pts)
    
    phi = PhiManip.phi_1D(xx)
    phi = PhiManip.phi_1D_to_2D(xx, phi)
    
    phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m12, m21=m21)
    fs = Spectrum.from_phi(phi, ns, (xx,xx))
    
    return fs    
```

```{python python_setup}
import os
import numpy
import dadi
import pylab
from datetime import datetime

#use dportik's functions
#get the optimize functions
execfile("../../programs/dadi_pipeline-master/Two_Population_Pipeline/Optimize_Functions.py")
execfile( "../../programs/dadi_pipeline-master/Two_Population_Pipeline/Models_2D.py")
execfile("../../scripts/250_custom_dadi_models.py")


# Load the data
dd = dadi.Misc.make_data_dict ( "fwsw75.dadi.snps" )
#projections is sample size of alleles
#need to use MINIMUM projections

#pops = ['FLLG', 'FLCC', 'ALFW','ALST','LAFW','TXFW','TXCC']
#projs = [70,      61,     72,     70,    72,    46,     61]

tx = dadi.Spectrum.from_data_dict(dd , pop_ids =[ 'TXFW','TXCC' ],projections =[46,60] ,polarized = False )  #polarized = False creates folded spectrum

```

So I'll try, step by step in ipython (after loading python_setup):


```{python asym_migfxn}
nu1 = 1.01
nu2 = 15.4299
m12 = 0.9824
m21 = 1.1719
T = 3.6611
ns = [46,60]

# First set of points
pts = 200
xx = Numerics.default_grid(pts)
phi = PhiManip.phi_1D(xx)
phi = PhiManip.phi_1D_to_2D(xx, phi)
phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m12, m21=m21)
fs200 = Spectrum.from_phi(phi, ns, (xx,xx))
    
```

Incredibly, this seemed to work, so now I'll run the other points settings (250,300) and plot the resulting spectra.

```{python pts}
# Second set of points
pts = 250
xx = Numerics.default_grid(pts)
phi = PhiManip.phi_1D(xx)
phi = PhiManip.phi_1D_to_2D(xx, phi)
phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m12, m21=m21)
fs250 = Spectrum.from_phi(phi, ns, (xx,xx))

# Third set of points
pts = 300
xx = Numerics.default_grid(pts)
phi = PhiManip.phi_1D(xx)
phi = PhiManip.phi_1D_to_2D(xx, phi)
phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m12, m21=m21)
fs300 = Spectrum.from_phi(phi, ns, (xx,xx))
```


```{python plot_pts_sfs}
dadi.Plotting.plot_single_2d_sfs(fs200,vmin=0.01)
dadi.Plotting.plot_single_2d_sfs(fs250,vmin=0.01)
dadi.Plotting.plot_single_2d_sfs(fs300,vmin=0.01)
```

![SFS with 200 points]("dadi_analysis/TX2D/asym_mig_200ptsTest.png")
![SFS with 250 points]("dadi_analysis/TX2D/asym_mig_250ptsTest.png")
![SFS with 300 points]("dadi_analysis/TX2D/asym_mig_300ptsTest.png")

I have no idea how to interpret these. They all look basically the same. I think maybe it's time to respond to Gutenkunst's suggestion.

First, actually, I'll try the same set of code but with parameters that didn't give warnings (`r opt_warns[sample(which(opt_warns$Model=="asym_mig" & opt_warns$Warning=="FALSE"),1),]`).

```{python asym_migGoodParams}
nu1 = 1.0101
nu2 = 8.5997
m12 = 0.3722
m21 = 0.8104
T = 0.7221
ns = [46,60]

# First set of points
pts = 200
xx = Numerics.default_grid(pts)
phi = PhiManip.phi_1D(xx)
phi = PhiManip.phi_1D_to_2D(xx, phi)
phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m12, m21=m21)
fs200 = Spectrum.from_phi(phi, ns, (xx,xx))
    
# Second set of points
pts = 250
xx = Numerics.default_grid(pts)
phi = PhiManip.phi_1D(xx)
phi = PhiManip.phi_1D_to_2D(xx, phi)
phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m12, m21=m21)
fs250 = Spectrum.from_phi(phi, ns, (xx,xx))

# Third set of points
pts = 300
xx = Numerics.default_grid(pts)
phi = PhiManip.phi_1D(xx)
phi = PhiManip.phi_1D_to_2D(xx, phi)
phi = Integration.two_pops(phi, xx, T, nu1, nu2, m12=m12, m21=m21)
fs300 = Spectrum.from_phi(phi, ns, (xx,xx))

# Plot
dadi.Plotting.plot_single_2d_sfs(fs200,vmin=0.01)
dadi.Plotting.plot_single_2d_sfs(fs250,vmin=0.01)
dadi.Plotting.plot_single_2d_sfs(fs300,vmin=0.01)
```

![Good Params SFS with 200 points]("dadi_analysis/TX2D/asym_mig_200ptsGoodParams.png")
![Good Params SFS with 250 points]("dadi_analysis/TX2D/asym_mig_250ptsGoodParams.png")
![Good Params SFS with 300 points]("dadi_analysis/TX2D/asym_mig_300ptsGoodParams.png")

I posted these results on the dadi forum because I really have no idea what to make of them. https://groups.google.com/forum/#!topic/dadi-user/7DHNai6wDb4

# 18 July 2019

I received a response back from Gutenkunst:

```
Hello Sarah,

Sorry to hear you’re running into this. The one standout from your script is that your passing in a list of 4 grid points for extrapolation, rather than the typical 3. So you’re doing a cubic rather than a quadratic extrapolation. It’s possible that that is less well-behaved. It certainly hasn’t been tested.

If you want to dig deeper, take one of the problematic parameter sets, evaluate the sfs for each individual grid point setting, and compare them with each other and with the eventual extrapolation. (For example, if you’re using pts=[20,30,40], you’d calculate with pts=[20], pts=[30], pts=[40] to get three spectra, then compare among them.) That will at least give you a more specific idea of where in the spectrum the problem is and what’s actually happening.

Best,
Ryan
```

So, now I have to figure out how to implement this. Some action items:

1. Obviously, I'll remove the extra pts setting -- though that shouldn't be an issue, since I added it hoping it would fix the warnings problem. [I did this, removed the 350]
2. Extract a problematic parameter set
3. Run dadi on each individual grid point setting for those parameters and compare the spectra. This step should probably be run in the interactive python environment?

From the 250_fwsw_dadi.Rmd: 

```{r dadiSetup}
knitr::opts_chunk$set(echo = TRUE,out.extra='',fig.pos="H")
knitr::opts_knit$set(root.dir='./fwsw_results/')
source("../../gwscaR/R/gwscaR.R")
source("../../gwscaR/R/gwscaR_plot.R")
source("../../gwscaR/R/gwscaR_utility.R")
source("../../gwscaR/R/gwscaR_fsts.R")
source("../../gwscaR/R/gwscaR_popgen.R")
source("../../gwscaR/R/vcf2dadi.R")
source("../R/250_dadi_analysis.R")
library(knitr)
pop.list<-c("ALFW","ALST","FLCC","FLLG","LAFW","TXCC","TXFW")
```
```{r getWarnings}
all_warnings<-lapply(list.files(pattern="251",path = "dadi_analysis",full.names = TRUE),dadi_warnings)
names(all_warnings)<-list.files(pattern="251",path = "dadi_analysis",full.names = FALSE)

#for now, focus on V1s
all_warnings<-all_warnings[c("251_2DTX_V1_1.log","251_2DTX_V1_2.log","251_2DTX_V1_3.log")] 
all_warnings<-lapply(all_warnings,function(dat) { 
  dat$Warning<-TRUE
  return(dat)
})
```

Now let's get the parameters
```{r getParams}
opt_files<-list.files(path = "dadi_analysis/TX2D",pattern="V.*optimized.*",full.names = TRUE)
opt_files<-opt_files[grep("V1",opt_files)] #focus on V1s
tx_opts<-do.call(rbind,lapply(opt_files,function(file){
  dat<-parse_dadi_opt(file)
  dat$file<-file
  return(dat)
}))
```

```{r MatchWarnings2params}
opt_warns<-do.call(rbind,mapply(function(warnings,name,opts){
  key<-gsub("251_2DTX_(V\\d)_(\\d).log","\\1_Number_\\2",name)
  dat<-merge(opts[grep(key,opts$file),],warnings,by=c("Model","Replicate"),all = TRUE)
  dat$Warning[is.na(dat$Warning)]<-FALSE
  return(dat)
},all_warnings,names(all_warnings),MoreArgs = list(opts=tx_opts),SIMPLIFY = FALSE))
```

Ok, so now I've got all the parameter combinations, let's choose a random set taht didn't work.

```{r chooseRandWarn}
opt_warns[sample(which(opt_warns$Warning==TRUE),size = 1),]
```

Ok, so looking at the manual, to run this chosen set of parameters:
                         Model            Replicate log.likelihood     AIC  chi.squared  theta                  optimized_params             params
251_2DTX_V1_2.log.243 asym_mig Round_3_Replicate_20       -1180.06 2370.12 -15550366.57 113.78 1.01,15.4299,0.9824,1.1719,3.6611 nu1,nu2,m12,m21,T.
                                                                       file Warning
251_2DTX_V1_2.log.243 dadi_analysis/TX2D/V1_Number_2.asym_mig.optimized.txt    TRUE

I need to specify the model like this:

```{python}
asym_mig([1.01,15.4299,0.9824,1.1719,3.6611], ns=[46,60] , pts=[200]) #ns are sample sizes
```


# 15 July 2019

I decided to post on the dadi forum regarding my 2D TX populations. Here is what I wrote:

```
Hi dadi community,

I'm trying to compare the fit of several models for an analysis between two populations and I'm consistently getting warnings that say
WARNING:Numerics:Extrapolation may have failed. Check resulting frequency spectrum for unexpected results.
WARNING:Inference:Model is masked in some entries where data is not.
These warnings do not go away as the model runs; they are just as likely in early runs as in later runs. Following answers to similar questions on this user group, I've tried increasing the number of points, narrowing the parameter bounds so that the model doesn't wander into difficult-to-escape parameter spaces, and using the make_extrap_func() instead of make_extrap_log_func(). However, I'm still getting these warnings pretty consistently, and not for any particular region of parameter space. I've attached a violin plot of the parameters for runs that produce warnings (left, red) and ones that don't produce warnings (right, grey) -- apologies for not making it a super pretty graph, but it conveys the idea that the parameter distributions are generally similar for the ones with warnings and the ones without. I'm getting these errors for both simple models (no migration) and complex models (ancient asymmetrical migration with population size changes). I chose the models after running 1D models for both populations, with the best fit for one population (TXCC) being growth or bottlegrowth and the best fit for the other population (TXFW) being either two_epoch or growth. The 2D frequency spectrum is attached as well.

I'm using a modified version of Daniel Portik's dadi_pipeline (https://github.com/dportik/dadi_pipeline) using the attached script. The in_params settings are ones taken from previous runs that did not produce warnings, but I get warnings whether I include those or not.

Can anyone help me understand why I'm getting these warnings and how to run the models successfully?

Thank you in advance!
```

I attached this script:
```{python, eval=FALSE}
'''
Running 2D model for TX pops
Run this from outside the dadi directory
'''

#start with ipython -pylab from ~/Research/popgen/fwsw_results/dadi_analysis/TX2D

# Numpy is the numerical library dadi is built upon
import sys
import os
import numpy
import dadi
import pylab
from datetime import datetime

#use dportik's functions
#get the optimize functions
execfile("../../programs/dadi_pipeline-master/Two_Population_Pipeline/Optimize_Functions.py")
execfile( "../../programs/dadi_pipeline-master/Two_Population_Pipeline/Models_2D.py")
execfile("../../scripts/250_custom_dadi_models.py")


# Load the data
dd = dadi.Misc.make_data_dict ( "fwsw75.dadi.snps" )
#projections is sample size of alleles
#need to use MINIMUM projections

#pops = ['FLLG', 'FLCC', 'ALFW','ALST','LAFW','TXFW','TXCC']
#projs = [70,      61,     72,     70,    72,    46,     61]

tx = dadi.Spectrum.from_data_dict(dd , pop_ids =[ 'TXFW','TXCC' ],projections =[46,60] ,polarized = False )  #polarized = False creates folded spectrum

os.chdir("TX2D")
#=================================================================================================#
#										PLOT SPECTRA	 										  #
#=================================================================================================#
dadi.Plotting.plot_single_2d_sfs(tx,vmin=0.01)


#=================================================================================================#
#										LOOP TO OPTIMIZE 										  #
#=================================================================================================#
pts = [ 200,250,300,350 ]
rounds=4
#define the lists for optional arguments
#you can change these to alter the settings of the optimization routine
reps = [10,20,30,40]
maxiters = [3,5,10,20]
folds = [3,2,2,1]
fs_folded = True
prefix = "tx"

for i in range(3,4):
	prefix = "V1_Number_{}".format(i)
	# Split into two populations, no migration.
	Optimize_Routine_Extrap(tx, pts, prefix, "no_mig", no_mig, rounds, 3, fs_folded=fs_folded, reps=reps, maxiters=maxiters, folds=folds, param_labels = "nu1, nu2, T",in_params=[1.01,9.73,0.25],in_upper=[20,20,10],in_lower=[1,1,0.01])

	# Split into two populations, with continuous symmetric migration.
	Optimize_Routine_Extrap(tx, pts, prefix, "sym_mig", sym_mig, rounds, 4, fs_folded=fs_folded, reps=reps, maxiters=maxiters, folds=folds, param_labels = "nu1, nu2, m, T",in_params=[1.01,9.77,0.60,1.09],in_upper=[20,20,10,10],in_lower=[1,1,0.01,0.01])

	# Split into two populations, with continuous asymmetric migration.
	Optimize_Routine_Extrap(tx, pts, prefix, "asym_mig", asym_mig, rounds, 5, fs_folded=fs_folded, reps=reps, maxiters=maxiters, folds=folds, param_labels = "nu1, nu2, m12, m21, T",in_params=[1.01,10.98,0.68,0.48,1.32],in_upper=[20,20,10,10,10],in_lower=[1,1,0.01,0.01,0.01])

	# Split with no migration, then instantaneous size change with no migration.
	Optimize_Routine_Extrap(tx, pts, prefix, "no_mig_size", no_mig_size, rounds, 6, fs_folded=fs_folded, reps=reps, maxiters=maxiters, folds=folds, param_labels = "nu1a, nu2a, nu1b, nu2b, T1, T2",in_params=[6.88,14.20,1.01,9.69,0.02,0.24],in_upper=[20,20,20,20,10,10],in_lower=[1,1,1,1,0.01,0.01])

	# Split with symmetric migration, then instantaneous size change with continuous symmetric migration.
	Optimize_Routine_Extrap(tx, pts, prefix, "sym_mig_size", sym_mig_size, rounds, 7, fs_folded=fs_folded, reps=reps, maxiters=maxiters, folds=folds, param_labels = "nu1a, nu2a, nu1b, nu2b, m, T1, T2",in_params=[14.75,2.53,1.01,14.93,0.50,0.98,0.60],in_upper=[20,20,20,20,10,10,10],in_lower=[1,1,1,1,0.01,0.01,0.01])

	# Split with different migration rates, then instantaneous size change with continuous asymmetric migration.
	Optimize_Routine_Extrap(tx, pts, prefix, "asym_mig_size", asym_mig_size, rounds, 8, fs_folded=fs_folded, reps=reps, maxiters=maxiters, folds=folds, param_labels = "nu1a, nu2a, nu1b, nu2b, m12, m21, T1, T2",in_params=[1.01,9,1.01,9.92,0.63,0.51,0.16,1.15],in_upper=[20,20,20,20,10,10,10,10],in_lower=[1,1,1,1,0.01,0.01,0.01,0.01])

	# Split with continuous symmetrical gene flow, followed by instantaneous size change with no migration.
	Optimize_Routine_Extrap(tx, pts, prefix, "anc_sym_mig_size", anc_sym_mig_size, rounds, 7, fs_folded=fs_folded, reps=reps, maxiters=maxiters, folds=folds, param_labels = "nu1a, nu2a, nu1b, nu2b, m, T1, T2",in_params=[1.88,10.50,1.01,15,6.95,1.77,0.24],in_upper=[20,20,20,20,10,10,10],in_lower=[1,1,1,1,0.01,0.01,0.01])

	# Split with continuous asymmetrical gene flow, followed by instantaneous size change with no migration.
	Optimize_Routine_Extrap(tx, pts, prefix, "anc_asym_mig_size", anc_asym_mig_size, rounds, 8, fs_folded=fs_folded, reps=reps, maxiters=maxiters, folds=folds, param_labels = "nu1a, nu2a, nu1b, nu2b, m12, m21, T1, T2",in_params=[1.34,7.49,1.01,15,9.76,7.66,1.34,0.25],in_upper=[20,20,20,20,10,10,10,10],in_lower=[1,1,1,1,0.01,0.01,0.01,0.01])


```

# 12 July 2019

So yesterday I did not get super far with the simulations, but today I'm going to focus first on the Texas population and dive into what parameter combinations are causing warnings. Meanwhile the 3D runs are going VERY slowly in the background.

I used existing functions (form previous analyses of FL2D runs) to visualize the parameters for each model in runs with warnings and ones without warnings. However, there are no obvious patterns arising. A bunch of them are different according to a wilcoxon rank test:
[1] "m21 is different in anc_asym_mig_size"
[1] "nu1b is different in anc_asym_mig_size"
[1] "nu2b is different in anc_asym_mig_size"
[1] "T1 is different in anc_asym_mig_size"
[1] "T2 is different in anc_asym_mig_size"
[1] "m is different in anc_sym_mig_size"
[1] "nu1b is different in anc_sym_mig_size"
[1] "nu2a is different in anc_sym_mig_size"
[1] "T2 is different in anc_sym_mig_size"
[1] "m12 is different in asym_mig"
[1] "m21 is different in asym_mig"
[1] "nu1 is different in asym_mig"
[1] "m21 is different in asym_mig_size"
[1] "nu1b is different in asym_mig_size"
[1] "nu2a is different in asym_mig_size"
[1] "T1 is different in asym_mig_size"
[1] "nu2a is different in no_mig_size"
[1] "T1 is different in no_mig_size"
[1] "m is different in sym_mig"
[1] "nu2 is different in sym_mig"
[1] "m is different in sym_mig_size"
[1] "nu1a is different in sym_mig_size"
[1] "nu2a is different in sym_mig_size"
[1] "nu2b is different in sym_mig_size"

but it's unclear to me how these issues can be fixed. All of these parameters seem to be ones that tend to be near the minimum or maximum values in parameter space.

I could try using other models -- that's what Gutenkunst suggests in one post: https://groups.google.com/forum/#!searchin/dadi-user/warning$20numerics$20extrapolation%7Csort:date/dadi-user/esRqfOQ7Amc/LfxsS0eog0IJ

# 11 July 2019

I'm not sure if this is the best way to go about doing this lab notebook thing, but I'm gonna give it a go. Today I'm trying to figure out how to analyze the $\delta_A\delta_I$ simulation results for the Florida populations. 

Portik used the simulated data to simply evaluate whether the empirical log-likelihoods and $\chi^2$ values are in the simulated distributions -- which I've done using the dadi-pipeline GOF R functions.

**How to implement heterogeneous migration, like in Tine et al. 2014 and Rougeux et al. 2017? $\delta_A\delta_I$??**
* The $\delta_A\delta_I$ user group has this response from Gutenkunst: "In your function, run through two sfs calculations, to create sfs1 and sfs2, then return `p*sfs1 + (1-p)*sfs2`."

**How to use simulations to analyze outlier data?**

**Updates on other $\delta_A\delta_I$ analyses:**
* Alabama & Louisiana analysis stopped after ~2.4 rounds of the first model results (possibly it's just slow, otherwise it could be an issue with the computer stalling)
* TX has lots of warnings - I want to delve into what's causing those by looking at the model output for the warning rounds.